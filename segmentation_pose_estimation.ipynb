{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b689bb6a",
   "metadata": {},
   "source": [
    "# EE267 Spring 2025 Term Project: Swimmer Segmentation and Pose Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d36b56",
   "metadata": {},
   "source": [
    "## Objective\n",
    "Articial Intelligence (AI) has transformed computer vision, enabling machines to interpret visual data\n",
    "much like humans. Two critical techniques in this field are image segmentation and human pose\n",
    "estimation. Image segmentation isolates objects from their backgrounds, essential for tasks like sports\n",
    "analysis and medical imaging. Human pose estimation, on the other hand, detects body joints and\n",
    "movement, providing valuable insights for elds such as biomechanics and augmented reality.\n",
    "\n",
    "In this assignment, we will do the following:\n",
    "1. Segment the swimmer from the background using Meta's Segment Anything Model (SAM).\n",
    "2. Detect and label the swimmer's joints using a human pose estimation model of your choice\n",
    "(either YOLO or Meta Sapiens)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b95dec",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5e79fe",
   "metadata": {},
   "source": [
    "### Task 0: Data Pre-processing\n",
    "\n",
    "Complete Guide to Image Preprocessing Techniques in Python: https://medium.com/@maahip1304/the-complete-guide-to-image-preprocessing-techniques-in-python-dca30804550c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "16a59d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import cv2\n",
    "\n",
    "# Data types\n",
    "from typing import List\n",
    "from numpy import ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d36524b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image dataset paths\n",
    "INPUT_FOLDER = 'data/input/'\n",
    "OUTPUT_FOLDER = 'data/output/'\n",
    "\n",
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b556c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all JPG and PNG images in input image folder\n",
    "images = glob(os.path.join(INPUT_FOLDER, '*.jpg')) + \\\n",
    "    glob(os.path.join(INPUT_FOLDER, '*.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9acd362",
   "metadata": {},
   "source": [
    "#### Image Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "557b5cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(images: List[ndarray]) -> List[ndarray]:\n",
    "    \"\"\"\n",
    "    Image pre-processing for image segmentation & pose estimation:\n",
    "    1. Resizing\n",
    "    2. Image denoising\n",
    "    3. Image enhancement\n",
    "    4. Normalization\n",
    "\n",
    "    Parameters:\n",
    "        images (List[ndarray]): images to pre-process\n",
    "\n",
    "    Returns:\n",
    "        List[ndarray]: post-processed images\n",
    "    \"\"\"\n",
    "    # Image resizing\n",
    "\n",
    "    # Grayscaling (probably not bc we want color)\n",
    "\n",
    "    # Image denoising: smoothing, blurring, filtering, sharpening\n",
    "    \"\"\" We won't want to smooth or blur for our use case. \n",
    "        In lecture professor said, the blue water and bubbles makes it hard to segment swimmers from rest of image. \n",
    "        If anything, we want to sharpen image & detect edges.\"\"\"\n",
    "\n",
    "    ## Edge-preserving smoothing filter: bilateral filter?\n",
    "\n",
    "    ## Image sharpening: Laplacian filter, Unsharp masking\n",
    "\n",
    "    ## Edge detection: Canny operator\n",
    "\n",
    "    # Image enhancement\n",
    "    ## Contrast enhancement: histogram equalization\n",
    "\n",
    "    # Normalization (pixel intensity)\n",
    "\n",
    "    # Batching\n",
    "    \n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7797144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process images\n",
    "processed_images = preprocess(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123b11e0",
   "metadata": {},
   "source": [
    "#### Image Augmentation (if needed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abe7600",
   "metadata": {},
   "source": [
    "### Task 1: Swimmer Segmentation with SAM\n",
    "Description:\n",
    "\n",
    "Use Meta’s SAM model to isolate the swimmer from each frame provided.\n",
    "\n",
    "Instructions:\n",
    "1. Load the provided dataset of swimmer images.\n",
    "2. Apply SAM to each image to segment the swimmer, separating them from the background.\n",
    "3. Save the segmented images for the next task.\n",
    "\n",
    "Meta SAM Github: https://github.com/facebookresearch/segment-anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82cd560b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21183f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU is available for PyTorch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "73c93268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Meta Segment Anything Model (SAM) variables\n",
    "MODEL_PATH = 'models/sam_vit_b_01ec64.pth'\n",
    "SAM_TYPE = 'vit_b'\n",
    "\n",
    "# Load Meta SAM variant\n",
    "sam_model = sam_model_registry[SAM_TYPE](checkpoint=MODEL_PATH)\n",
    "sam_model.to(device=device)\n",
    "\n",
    "# Create an automatic mask generator using SAM\n",
    "mask_generator = SamAutomaticMaskGenerator(sam_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d66746a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment(image: ndarray) -> ndarray:\n",
    "    \"\"\"\n",
    "    Segment swimmer in image\n",
    "\n",
    "    Parameters:\n",
    "        images (ndarray): image to segment\n",
    "\n",
    "    Returns:\n",
    "        ndarray: segmented image\n",
    "    \"\"\"\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "68a2f601",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_dataset(images: List[ndarray]) -> List[ndarray]:\n",
    "    \"\"\"\n",
    "    Segment swimmer in image\n",
    "\n",
    "    Parameters:\n",
    "        images (List[ndarray]): image dataset to segment\n",
    "\n",
    "    Returns:\n",
    "        List[ndarray]: segmented image dataset\n",
    "    \"\"\"\n",
    "    return [segment(image) for image in images]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038cc421",
   "metadata": {},
   "source": [
    "### Task 2: Pose Estimation on the Segmented Swimmer\n",
    "\n",
    "Description:\n",
    "\n",
    "With the segmented swimmer images, utilize a human pose estimation model to\n",
    "detect the swimmer’s joints.\n",
    "\n",
    "Model Options:\n",
    "1. YOLO (congured for pose estimation).\n",
    "2. Meta Sapiens\n",
    "\n",
    "Instructions:\n",
    "1. Choose either YOLO or Meta Sapiens for pose estimation.\n",
    "2. Run the selected model on the segmented images to identify key joint positions.\n",
    "3. Save images with overlaid joint positions and export joint coordinates for each frame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4862b262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Pose Estimation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cb08f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify key joint positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f182135c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overlay images with joint positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7525f375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save overlaid images"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
